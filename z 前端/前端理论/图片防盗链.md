

图片防盗链通常是通过服务器端进行设置的，主要是通过检查 HTTP 请求头中的 `Referer` 或 `Origin` 字段来实现的。如果这些字段的值不是预期的值（例如，不是你的网站的域名），那么服务器就不会返回图片的内容，从而实现防盗链。

以下是一个使用 Node.js 和 Express 实现图片防盗链的简单示例：

```
const express = require ('express');
const app = express ();

app.use ('/images', function (req, res, next) {
  const referer = req. headers. referer;
  if (referer) {
    const refererHost = new URL (referer). host;
    if (refererHost !== 'your-website. com') {
      // 如果 Referer 不是你的网站的域名，返回一个错误图片或者错误信息
      res.sendFile ('/path/to/error. png');
      return;
    }
  }
  next ();
});

app.listen (3000, function () {
  console.log ('Server is listening on port 3000');
});
```




这样子的图片防盗链只能让用户无法直接访问图片的链接，黑客可以通过服务端请求轻松修改请求头的信息模拟真实设备请求从而得到我们的图片。

## 防止爬虫爬取

防止 Node.js 爬虫（或任何类型的爬虫）爬取图片是一个复杂的问题，因为爬虫可以模拟正常用户的行为。然而，有一些策略可以帮助你增加爬虫获取图片的难度：

1. **Robots.txt**: 这是一个简单的方法，你可以在你的网站的根目录下放置一个 `robots.txt` 文件，告诉爬虫哪些路径不应该被爬取。然而，这个方法依赖于爬虫遵守 `robots.txt` 文件，恶意的爬虫可能会忽略这个文件。
    
2. **User-Agent检查**: 你可以检查 HTTP 请求头中的 `User-Agent` 字段，如果它是一个已知的爬虫，你可以拒绝请求。然而，爬虫可以伪造 `User-Agent` 字段，所以这个方法并不完全可靠。
    
3. **Rate Limiting**: 你可以限制来自同一 IP 地址的请求频率。如果一个 IP 地址在短时间内发出了大量的请求，你可以暂时或永久地封锁这个 IP 地址。这个方法可以有效地阻止爬虫，但可能会误伤正常用户。
    
4. **CAPTCHA**: 你可以使用 CAPTCHA（如 Google 的 reCAPTCHA）来验证用户是否是人类。如果一个用户（或爬虫）连续请求多次图片，你可以要求他们完成一个 CAPTCHA 验证。
    
5. **图片水印**: 你可以在你的图片上添加水印。即使爬虫能够下载图片，他们也无法去除水印。这可以防止他们使用你的图片。
    
6. **图片转换为 Base64**: 你可以将图片转换为 Base64 编码，然后在 HTML 中直接使用这个编码。这样，爬虫无法直接通过 URL 获取图片。